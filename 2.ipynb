{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy\nimport matplotlib.pyplot\n%matplotlib inline\n \n#데이터를 불러오고 그 파일을 읽는다.\ndata_file = open(\"mnist_train_100.csv\",'r')\ndata_list = data_file.readlines()\ndata_file.close()\n \nall_values = data_list[0].split(',') #split는 구분자로 사용할 기호를 그 매개변수로 가진다. 리스트를 불러와서 쉼표로 구분하여 분리\n#asfarray는 문자열을 실수로 변환한 다음에 그 숫자로 구성된 배열을 생성한다.\n#reshape((28,28))함수는 784개의 어레이 숫자들을 28 x 28 형태의 정방 행렬로 만들어 준다\nimage_array = numpy.asfarray(all_values[1:]).reshape((28,28)) #리스트의 원소중 가장 첫 번째 원소는 이 원소들이 무엇을 표현하는 것인지를 알려주는 것이기 때문에 빼준다.\nmatplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None') #imshow를 이용해 어레이를 시각화",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "<matplotlib.image.AxesImage at 0x7fa1e59a7940>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAADmVJREFUeJzt3X+MVPW5x/HPI4KoEIOyUGLxbtuouYakWx1JDWL2UiXUNAGCNSWxoZF0G63JxRBTs39Yf+QaYi6tGE2T7QXBpLVUAcHEtCgx8ZJodfxVRdSqWcteEJaoVIjSAM/9Yw/NijvfGWbOzBn2eb8SszPnOd89jwMfzsx858zX3F0A4jmt6AYAFIPwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8I6vRWHmzy5Mne2dnZykMCofT392v//v1Wy74Nhd/M5klaJWmMpP9x9xWp/Ts7O1Uulxs5JICEUqlU8751P+03szGSHpL0fUmXSFpsZpfU+/sAtFYjr/lnSnrP3T9w939K+oOk+fm0BaDZGgn/+ZJ2Dbs/kG37EjPrMbOymZUHBwcbOByAPDUS/pHeVPjK9cHu3ufuJXcvdXR0NHA4AHlqJPwDkqYPu/91SbsbawdAqzQS/pckXWhm3zCzcZJ+JGlLPm0BaLa6p/rc/YiZ3SLpzxqa6lvj7jty6wxAUzU0z+/uT0l6KqdeALQQH+8FgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqIZW6TWzfkmfSToq6Yi7l/JoCvk5duxYsn748OGmHn/dunUVa4cOHUqOfeutt5L1+++/P1nv7e2tWHvwwQeTY88888xkfeXKlcn6TTfdlKy3g4bCn/kPd9+fw+8B0EI87QeCajT8Lmmrmb1sZj15NASgNRp92j/L3Xeb2RRJT5vZ2+7+3PAdsn8UeiTpggsuaPBwAPLS0Jnf3XdnP/dJ2iRp5gj79Ll7yd1LHR0djRwOQI7qDr+ZnW1mE4/fljRX0pt5NQaguRp52j9V0iYzO/57fu/uf8qlKwBNV3f43f0DSd/OsZdR68CBA8n60aNHk/XXX389Wd+6dWvF2qeffpoc29fXl6wXqbOzM1lfvnx5sr569eqKtXPOOSc5dvbs2cn6nDlzkvVTAVN9QFCEHwiK8ANBEX4gKMIPBEX4gaDyuKovvIGBgWS9q6srWf/kk0/ybOeUcdpp6XNPaqpOqn7Z7dKlSyvWpkyZkhw7YcKEZH00fFqVMz8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBMU8fw7OO++8ZH3q1KnJejvP88+dOzdZr/b/vnHjxoq1M844Izm2u7s7WUdjOPMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFDM8+eg2nXla9euTdYff/zxZP2KK65I1hctWpSsp1x55ZXJ+ubNm5P1cePGJesfffRRxdqqVauSY9FcnPmBoAg/EBThB4Ii/EBQhB8IivADQRF+IChz9/QOZmsk/UDSPnefkW07V9J6SZ2S+iVd7+5VL0ovlUpeLpcbbHn0OXz4cLJebS69t7e3Yu2+++5Ljn322WeT9auuuipZR3splUoql8tWy761nPnXSpp3wrbbJW1z9wslbcvuAziFVA2/uz8n6eMTNs+XtC67vU7Sgpz7AtBk9b7mn+rueyQp+5le+whA22n6G35m1mNmZTMrDw4ONvtwAGpUb/j3mtk0Scp+7qu0o7v3uXvJ3UujYXFDYLSoN/xbJC3Jbi+RlL70C0DbqRp+M3tU0vOSLjazATNbKmmFpGvM7G+SrsnuAziFVL2e390XVyh9L+dewqr2/fXVTJo0qe6xDzzwQLI+e/bsZN2spilltCE+4QcERfiBoAg/EBThB4Ii/EBQhB8Iiq/uHgWWLVtWsfbiiy8mx27atClZ37FjR7I+Y8aMZB3tizM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTFPP8okPpq776+vuTYbdu2Jevz589P1hcsSH9366xZsyrWFi5cmBzL5cLNxZkfCIrwA0ERfiAowg8ERfiBoAg/EBThB4KqukR3nliiu/1Uu95/3rwTF2j+sgMHDtR97DVr1iTrixYtStYnTJhQ97FHq7yX6AYwChF+ICjCDwRF+IGgCD8QFOEHgiL8QFBVr+c3szWSfiBpn7vPyLbdKemnkgaz3Xrd/almNYnmmTlzZrJe7Xv7b7311mT9scceq1i78cYbk2Pff//9ZP22225L1idOnJisR1fLmX+tpJE+6fFrd+/K/iP4wCmmavjd/TlJH7egFwAt1Mhr/lvM7K9mtsbMJuXWEYCWqDf8v5H0LUldkvZIWllpRzPrMbOymZUHBwcr7QagxeoKv7vvdfej7n5M0m8lVXzXyN373L3k7qWOjo56+wSQs7rCb2bTht1dKOnNfNoB0Cq1TPU9Kqlb0mQzG5D0S0ndZtYlySX1S/pZE3sE0ARcz4+GfPHFF8n6Cy+8ULF29dVXJ8dW+7t53XXXJevr169P1kcjrucHUBXhB4Ii/EBQhB8IivADQRF+ICiW6EZDxo8fn6x3d3dXrI0ZMyY59siRI8n6E088kay/8847FWsXX3xxcmwEnPmBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjm+ZG0e/fuZH3jxo3J+vPPP1+xVm0ev5rLL788Wb/ooosa+v2jHWd+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiKef5RrtoSaQ899FCy/vDDDyfrAwMDJ91Trapd79/Z2Zmsm9X0DdZhceYHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaCqzvOb2XRJj0j6mqRjkvrcfZWZnStpvaROSf2Srnf3T5rXalwHDx5M1p988smKtbvvvjs59t13362rpzzMmTMnWV+xYkWyftlll+XZTji1nPmPSFru7v8u6buSfm5ml0i6XdI2d79Q0rbsPoBTRNXwu/sed38lu/2ZpJ2Szpc0X9K6bLd1khY0q0kA+Tup1/xm1inpO5L+Immqu++Rhv6BkDQl7+YANE/N4TezCZI2SFrm7v84iXE9ZlY2s3K1z5kDaJ2awm9mYzUU/N+5+/FvbNxrZtOy+jRJ+0Ya6+597l5y91JHR0cePQPIQdXw29ClUasl7XT3Xw0rbZG0JLu9RNLm/NsD0Cy1XNI7S9KPJb1hZq9l23olrZD0RzNbKunvkn7YnBZPfYcOHUrWd+3alazfcMMNyfqrr7560j3lZe7cucn6XXfdVbFW7au3uSS3uaqG3923S6r0p/C9fNsB0Cp8wg8IivADQRF+ICjCDwRF+IGgCD8QFF/dXaPPP/+8Ym3ZsmXJsdu3b0/W33777bp6ysO1116brN9xxx3JeldXV7I+duzYk+4JrcGZHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCCjPP39/fn6zfe++9yfozzzxTsfbhhx/W01JuzjrrrIq1e+65Jzn25ptvTtbHjRtXV09of5z5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCoMPP8GzZsSNZXr17dtGNfeumlyfrixYuT9dNPT/8x9fT0VKyNHz8+ORZxceYHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaDM3dM7mE2X9Iikr0k6JqnP3VeZ2Z2SfippMNu1192fSv2uUqnk5XK54aYBjKxUKqlcLlst+9byIZ8jkpa7+ytmNlHSy2b2dFb7tbv/d72NAihO1fC7+x5Je7Lbn5nZTknnN7sxAM11Uq/5zaxT0nck/SXbdIuZ/dXM1pjZpApjesysbGblwcHBkXYBUICaw29mEyRtkLTM3f8h6TeSviWpS0PPDFaONM7d+9y95O6ljo6OHFoGkIeawm9mYzUU/N+5+0ZJcve97n7U3Y9J+q2kmc1rE0DeqobfzEzSakk73f1Xw7ZPG7bbQklv5t8egGap5d3+WZJ+LOkNM3st29YrabGZdUlySf2SftaUDgE0RS3v9m+XNNK8YXJOH0B74xN+QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoKp+dXeuBzMblPThsE2TJe1vWQMnp117a9e+JHqrV569/Zu71/R9eS0N/1cOblZ291JhDSS0a2/t2pdEb/Uqqjee9gNBEX4gqKLD31fw8VPatbd27Uuit3oV0luhr/kBFKfoMz+AghQSfjObZ2bvmNl7ZnZ7ET1UYmb9ZvaGmb1mZoUuKZwtg7bPzN4ctu1cM3vazP6W/RxxmbSCervTzP4ve+xeM7NrC+ptupk9a2Y7zWyHmf1ntr3Qxy7RVyGPW8uf9pvZGEnvSrpG0oCklyQtdve3WtpIBWbWL6nk7oXPCZvZVZIOSnrE3Wdk2+6T9LG7r8j+4Zzk7r9ok97ulHSw6JWbswVlpg1fWVrSAkk/UYGPXaKv61XA41bEmX+mpPfc/QN3/6ekP0iaX0Afbc/dn5P08Qmb50tal91ep6G/PC1Xobe24O573P2V7PZnko6vLF3oY5foqxBFhP98SbuG3R9Qey357ZK2mtnLZtZTdDMjmJotm358+fQpBfdzoqorN7fSCStLt81jV8+K13krIvwjrf7TTlMOs9z9Uknfl/Tz7OktalPTys2tMsLK0m2h3hWv81ZE+AckTR92/+uSdhfQx4jcfXf2c5+kTWq/1Yf3Hl8kNfu5r+B+/qWdVm4eaWVptcFj104rXhcR/pckXWhm3zCzcZJ+JGlLAX18hZmdnb0RIzM7W9Jctd/qw1skLcluL5G0ucBevqRdVm6utLK0Cn7s2m3F60I+5JNNZdwvaYykNe7+Xy1vYgRm9k0Nne2loUVMf19kb2b2qKRuDV31tVfSLyU9IemPki6Q9HdJP3T3lr/xVqG3bg09df3Xys3HX2O3uLcrJf2vpDckHcs292ro9XVhj12ir8Uq4HHjE35AUHzCDwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUP8PRZ8Vlgh2BcUAAAAASUVORK5CYII=\n",
            "text/plain": "<Figure size 432x288 with 1 Axes>"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "raw",
      "source": "import numpy\n# scipy.special for the sigmoid function expit()\nimport scipy.special\n# library for plotting arrays\nimport matplotlib.pyplot\n# ensure the plots are inside this notebook, not an external window\n%matplotlib inline\n\n\n# neural network class definition\n# http://blog.naver.com/PostView.nhn?blogId=beodeulpiri&logNo=221025358671&parentCategoryNo=&categoryNo=&viewDate=&isShowPopularPosts=false&from=postView\n\n\n# neural network class definition\nclass neuralNetwork:\n    \n    \n    # initialise the neural network\n    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n        # set number of nodes in each input, hidden, output layer\n        self.inodes = inputnodes\n        self.hnodes = hiddennodes\n        self.onodes = outputnodes\n        \n        # link weight matrices, wih and who\n        # weights inside the arrays are w_i_j, where link is from node i to node j in the next layer\n        # w11 w21\n        # w12 w22 etc \n        self.wih = numpy.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n        self.who = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n\n        # learning rate\n        self.lr = learningrate\n        \n        # activation function is the sigmoid function\n        self.activation_function = lambda x: scipy.special.expit(x)\n        \n        pass\n\n    \n    # train the neural network\n    def train(self, inputs_list, targets_list):\n        # convert inputs list to 2d array\n        inputs = numpy.array(inputs_list, ndmin=2).T\n        targets = numpy.array(targets_list, ndmin=2).T\n        \n        # calculate signals into hidden layer\n        hidden_inputs = numpy.dot(self.wih, inputs)\n        # calculate the signals emerging from hidden layer\n        hidden_outputs = self.activation_function(hidden_inputs)\n        \n        # calculate signals into final output layer\n        final_inputs = numpy.dot(self.who, hidden_outputs)\n        # calculate the signals emerging from final output layer\n        final_outputs = self.activation_function(final_inputs)\n        \n        # output layer error is the (target - actual)\n        output_errors = targets - final_outputs\n        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n        hidden_errors = numpy.dot(self.who.T, output_errors) \n        \n        # update the weights for the links between the hidden and output layers\n        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n        \n        # update the weights for the links between the input and hidden layers\n        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n        \n        pass\n\n    \n    # query the neural network\n    def query(self, inputs_list):\n        # convert inputs list to 2d array\n        inputs = numpy.array(inputs_list, ndmin=2).T\n        \n        # calculate signals into hidden layer\n        hidden_inputs = numpy.dot(self.wih, inputs)\n        # calculate the signals emerging from hidden layer\n        hidden_outputs = self.activation_function(hidden_inputs)\n        \n        # calculate signals into final output layer\n        final_inputs = numpy.dot(self.who, hidden_outputs)\n        # calculate the signals emerging from final output layer\n        final_outputs = self.activation_function(final_inputs)\n        \n        return final_outputs\n\t# number of input, hidden and output nodes\n# 입력, 은닉, 출력 계층의 노드 개수 설정\n\ninput_nodes = 784\nhidden_nodes = 200\noutput_nodes = 10\n\n# 학습률\nlearning_rate = 0.1\n\n# 인공 신경망 생성\nn = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)\n\n# load the mnist training data CSV file into a list\ntraining_data_file = open(\"mnist_train_100.csv\", 'r')\ntraining_data_list = training_data_file.readlines()\ntraining_data_file.close()\n\n\n# train the neural network\n# epochs is the number of times the training data set is used for training\n\nepochs = 5\n\n\nfor e in range(epochs):\n    # go through all records in the training data set\n    for record in training_data_list:\n        # split the record by the ',' commas\n        all_values = record.split(',')\n        # scale and shift the inputs\n        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n        # create the target output values (all 0.01, except the desired label which is 0.99)\n        targets = numpy.zeros(output_nodes) + 0.01\n        # all_values[0] is the target label for this record\n        targets[int(all_values[0])] = 0.99\n        n.train(inputs, targets)\n        pass\n    pass\n\n#이젠 테스트 데이타를 로딩한다.\n# load the mnist test data CSV file into a list\ntest_data_file = open(\"mnist_test_10.csv\", 'r')\ntest_data_list = test_data_file.readlines()\ntest_data_file.close()\n\n\n\n#테스트 데이타 첫번째 값을 보면 7 이다는 것을 알 수 있다.\n\nall_values = test_data_list[0].split(',')\nprint(all_values[0])\nimage_array = numpy.asfarray(all_values[1:]).reshape((28,28))\nmatplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\nimport numpy\n# scipy.special for the sigmoid function expit()\nimport scipy.special\n# library for plotting arrays\nimport matplotlib.pyplot\n# ensure the plots are inside this notebook, not an external window\n%matplotlib inline\n\n\n# neural network class definition\n# http://blog.naver.com/PostView.nhn?blogId=beodeulpiri&logNo=221025358671&parentCategoryNo=&categoryNo=&viewDate=&isShowPopularPosts=false&from=postView\nclass neuralNetwork:\n    \n    \n    # initialise the neural network\n    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n        # set number of nodes in each input, hidden, output layer\n        self.inodes = inputnodes\n        self.hnodes = hiddennodes\n        self.onodes = outputnodes\n        \n        # link weight matrices, wih and who\n        # weights inside the arrays are w_i_j, where link is from node i to node j in the next layer\n        # w11 w21\n        # w12 w22 etc \n        self.wih = numpy.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n        self.who = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n\n        # learning rate\n        self.lr = learningrate\n        \n        # activation function is the sigmoid function\n        self.activation_function = lambda x: scipy.special.expit(x)\n        \n        pass\n\n    \n    # train the neural network\n    def train(self, inputs_list, targets_list):\n        # convert inputs list to 2d array\n        inputs = numpy.array(inputs_list, ndmin=2).T\n        targets = numpy.array(targets_list, ndmin=2).T\n        \n        # calculate signals into hidden layer\n        hidden_inputs = numpy.dot(self.wih, inputs)\n        # calculate the signals emerging from hidden layer\n        hidden_outputs = self.activation_function(hidden_inputs)\n        \n        # calculate signals into final output layer\n        final_inputs = numpy.dot(self.who, hidden_outputs)\n        # calculate the signals emerging from final output layer\n        final_outputs = self.activation_function(final_inputs)\n        \n        # output layer error is the (target - actual)\n        output_errors = targets - final_outputs\n        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n        hidden_errors = numpy.dot(self.who.T, output_errors) \n        \n        # update the weights for the links between the hidden and output layers\n        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n        \n        # update the weights for the links between the input and hidden layers\n        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n        \n        pass\n\n    \n    # query the neural network\n    def query(self, inputs_list):\n        # convert inputs list to 2d array\n        inputs = numpy.array(inputs_list, ndmin=2).T\n        \n        # calculate signals into hidden layer\n        hidden_inputs = numpy.dot(self.wih, inputs)\n        # calculate the signals emerging from hidden layer\n        hidden_outputs = self.activation_function(hidden_inputs)\n        \n        # calculate signals into final output layer\n        final_inputs = numpy.dot(self.who, hidden_outputs)\n        # calculate the signals emerging from final output layer\n        final_outputs = self.activation_function(final_inputs)\n        \n        return final_outputs\n\t# number of input, hidden and output nodes\ninput_nodes = 784\nhidden_nodes = 200\noutput_nodes = 10\n\n# learning rate\nlearning_rate = 0.1\n\n# create instance of neural network\nn = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)\n# load the mnist training data CSV file into a list\ntraining_data_file = open(\"mnist_train_100.csv\", 'r')\ntraining_data_list = training_data_file.readlines()\ntraining_data_file.close()\n\n# train the neural network\n\n# epochs is the number of times the training data set is used for training\nepochs = 5\n\nfor e in range(epochs):\n    # go through all records in the training data set\n    for record in training_data_list:\n        # split the record by the ',' commas\n        all_values = record.split(',')\n        # scale and shift the inputs\n        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n        # create the target output values (all 0.01, except the desired label which is 0.99)\n        targets = numpy.zeros(output_nodes) + 0.01\n        # all_values[0] is the target label for this record\n        targets[int(all_values[0])] = 0.99\n        n.train(inputs, targets)\n        pass\n    pass\n# load the mnist test data CSV file into a list\ntest_data_file = open(\"mnist_test_10.csv\", 'r')\ntest_data_list = test_data_file.readlines()\ntest_data_file.close()\n\n# test the neural network\n\n# scorecard for how well the network performs, initially empty\nscorecard = []\n\n# go through all the records in the test data set\nfor record in test_data_list:\n    # split the record by the ',' commas\n    all_values = record.split(',')\n    # correct answer is first value\n    correct_label = int(all_values[0])\n    # scale and shift the inputs\n    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n    # query the network\n    outputs = n.query(inputs)\n    # the index of the highest value corresponds to the label\n    label = numpy.argmax(outputs)\n    # append correct or incorrect to list\n    if (label == correct_label):\n        # network's answer matches correct answer, add 1 to scorecard\n        scorecard.append(1)\n    else:\n        # network's answer doesn't match correct answer, add 0 to scorecard\n        scorecard.append(0)\n        pass\n    \n    pass\n\n# calculate the performance score, the fraction of correct answers\nscorecard_array = numpy.asarray(scorecard)\nprint (\"performance = \", scorecard_array.sum() / scorecard_array.size)\nimport numpy\n# scipy.special for the sigmoid function expit()\nimport scipy.special\n# library for plotting arrays\nimport matplotlib.pyplot\n# ensure the plots are inside this notebook, not an external window\n%matplotlib inline\n\n\n# neural network class definition\nclass neuralNetwork:\n    \n    \n    # initialise the neural network\n    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n        # set number of nodes in each input, hidden, output layer\n        self.inodes = inputnodes\n        self.hnodes = hiddennodes\n        self.onodes = outputnodes\n        \n        # link weight matrices, wih and who\n        # weights inside the arrays are w_i_j, where link is from node i to node j in the next layer\n        # w11 w21\n        # w12 w22 etc \n        self.wih = numpy.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n        self.who = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n\n        # learning rate\n        self.lr = learningrate\n        \n        # activation function is the sigmoid function\n        self.activation_function = lambda x: scipy.special.expit(x)\n        \n        pass\n\n    \n    # train the neural network\n    def train(self, inputs_list, targets_list):\n        # convert inputs list to 2d array\n        inputs = numpy.array(inputs_list, ndmin=2).T\n        targets = numpy.array(targets_list, ndmin=2).T\n        \n        # calculate signals into hidden layer\n        hidden_inputs = numpy.dot(self.wih, inputs)\n        # calculate the signals emerging from hidden layer\n        hidden_outputs = self.activation_function(hidden_inputs)\n        \n        # calculate signals into final output layer\n        final_inputs = numpy.dot(self.who, hidden_outputs)\n        # calculate the signals emerging from final output layer\n        final_outputs = self.activation_function(final_inputs)\n        \n        # output layer error is the (target - actual)\n        output_errors = targets - final_outputs\n        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n        hidden_errors = numpy.dot(self.who.T, output_errors) \n        \n        # update the weights for the links between the hidden and output layers\n        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n        \n        # update the weights for the links between the input and hidden layers\n        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n        \n        pass\n\n    \n    # query the neural network\n    def query(self, inputs_list):\n        # convert inputs list to 2d array\n        inputs = numpy.array(inputs_list, ndmin=2).T\n        \n        # calculate signals into hidden layer\n        hidden_inputs = numpy.dot(self.wih, inputs)\n        # calculate the signals emerging from hidden layer\n        hidden_outputs = self.activation_function(hidden_inputs)\n        \n        # calculate signals into final output layer\n        final_inputs = numpy.dot(self.who, hidden_outputs)\n        # calculate the signals emerging from final output layer\n        final_outputs = self.activation_function(final_inputs)\n        \n        return final_outputs\n\t# number of input, hidden and output nodes\n# 입력, 은닉, 출력 계층의 노드 개수 설정\n\ninput_nodes = 784\nhidden_nodes = 200\noutput_nodes = 10\n\n# 학습률\nlearning_rate = 0.1\n\n# 인공 신경망 생성\nn = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)\n\n# load the mnist training data CSV file into a list\ntraining_data_file = open(\"mnist_train_100.csv\", 'r')\ntraining_data_list = training_data_file.readlines()\ntraining_data_file.close()\n\n\n# train the neural network\n# epochs is the number of times the training data set is used for training\n\nepochs = 5\n\n\nfor e in range(epochs):\n    # go through all records in the training data set\n    for record in training_data_list:\n        # split the record by the ',' commas\n        all_values = record.split(',')\n        # scale and shift the inputs\n        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n        # create the target output values (all 0.01, except the desired label which is 0.99)\n        targets = numpy.zeros(output_nodes) + 0.01\n        # all_values[0] is the target label for this record\n        targets[int(all_values[0])] = 0.99\n        n.train(inputs, targets)\n        pass\n    pass\n\n#이젠 테스트 데이타를 로딩한다.\n# load the mnist test data CSV file into a list\ntest_data_file = open(\"mnist_test_10.csv\", 'r')\ntest_data_list = test_data_file.readlines()\ntest_data_file.close()\n\n\n\n#테스트 데이타 첫번째 값을 보면 7 이다는 것을 알 수 있다.\n\nall_values = test_data_list[3].split(',')\nprint(all_values[0])\nimage_array = numpy.asfarray(all_values[1:]).reshape((28,28))\nmatplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "performance =  0.6\n0\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "<matplotlib.image.AxesImage at 0x7fa1e59f5390>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": "<Figure size 432x288 with 1 Axes>"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport math\n\n# Sigmoid Function\ndef act(x):\n    return 1/(1+np.exp(-x))\n\n\n# datasets\nx = np.array([[0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1]])     # x1 and x2 in the same aisle is a set input node\ny = np.array([[0, 1, 1, 0]]).T     # xor\n\n\n# parameters\ninput_size = x.shape[1] # original input + bias\nhidden_size = 4\noutput_size = 1\nalpha = 0.1    # learning rate\nfalpha = 5\n\n\n# weights\nw1 = np.random.randn(input_size, hidden_size)\nw2 = np.random.randn(hidden_size, output_size)\n\ni=0\n\n\nwhile True:\n\t# forward\n\tz1 = np.dot(x, w1)\n\ta1 = act(z1)\n\tz2 = np.dot(a1, w2)\n\tY = act(z2)\n\t\n\t# back propagation\n\tdelta2 = (Y-y) * (Y * (1-Y))\n\tdelta1 = np.dot(delta2, w2.T) * (a1 * (1-a1))\n\tw2 -= alpha * np.dot(a1.T, delta2)\n\tw1 -= alpha * np.dot(x.T, delta1)\n\n\ti+=1\n\tif math.sqrt(sum((Y-y)**2)/4) < 0.05:\n\t\tbreak\n\n\n# test\nz1 = np.dot(x, w1)\na1 = act(z1)\nz2 = np.dot(a1, w2)\nY = act(z2)\nprint \nprint (\"Output after training...\")\nprint (Y)\nprint \nprint (\"Total Iteration is \"), i\n",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Output after training...\n[[0.03565259]\n [0.94830629]\n [0.94692925]\n [0.05689957]]\nTotal Iteration is \n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "(None, 9864)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}